name: Docker E2E Tests

on:
  workflow_dispatch: # Manual trigger
  push:
    branches: [main] # Trigger on merge to main

env:
  IMAGE_NAME: looplia:test

jobs:
  # Build Docker image once and share with all test jobs
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Build project
        run: bun run build

      - name: Build Docker image
        run: docker build -t $IMAGE_NAME .

      - name: Save Docker image
        run: docker save $IMAGE_NAME | gzip > looplia-image.tar.gz

      - name: Upload Docker image
        uses: actions/upload-artifact@v4
        with:
          name: docker-image
          path: looplia-image.tar.gz
          retention-days: 1

  # Test 1: Markdown (run command)
  test-markdown:
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: gunzip -c looplia-image.tar.gz | docker load

      - name: Create test workspace
        run: mkdir -p test-workspace-markdown

      - name: Run pipeline command
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          CONTAINER_ID=$(docker create \
            -e CLAUDE_CODE_OAUTH_TOKEN="$CLAUDE_CODE_OAUTH_TOKEN" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            run --file /examples/ai-healthcare.md \
            --topics "ai,healthcare,technology" \
            --tone "expert")

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-markdown/
          docker rm "$CONTAINER_ID"

      - name: Validate kit schema
        run: |
          echo "Validating kit schema..."
          SESSION_DIR=$(find test-workspace-markdown/contentItem -maxdepth 1 -type d ! -name contentItem | head -1)
          echo "Session folder: $SESSION_DIR"
          jq -e '.contentId and .summary and .ideas and .suggestedOutline' "$SESSION_DIR/writing-kit.json"
          echo "Kit schema valid"

      - name: Validate kit quality
        run: |
          echo "Checking kit quality metrics..."
          SESSION_DIR=$(find test-workspace-markdown/contentItem -maxdepth 1 -type d ! -name contentItem | head -1)
          HOOK_COUNT=$(jq '.ideas.hooks | length' "$SESSION_DIR/writing-kit.json")
          ANGLE_COUNT=$(jq '.ideas.angles | length' "$SESSION_DIR/writing-kit.json")
          QUESTION_COUNT=$(jq '.ideas.questions | length' "$SESSION_DIR/writing-kit.json")
          SECTION_COUNT=$(jq '.suggestedOutline | length' "$SESSION_DIR/writing-kit.json")

          echo "Hook count: $HOOK_COUNT (expected: >= 2)"
          echo "Angle count: $ANGLE_COUNT (expected: >= 2)"
          echo "Question count: $QUESTION_COUNT (expected: >= 2)"
          echo "Outline sections: $SECTION_COUNT (expected: >= 3)"

          [ "$HOOK_COUNT" -ge 2 ] || (echo "Hook count too low" && exit 1)
          [ "$SECTION_COUNT" -ge 3 ] || (echo "Outline section count too low" && exit 1)

          echo "Kit quality acceptable"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-markdown
          path: test-workspace-markdown/
          retention-days: 7

  # Test 2: VTT Caption (run command)
  test-vtt:
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: gunzip -c looplia-image.tar.gz | docker load

      - name: Create test workspace
        run: mkdir -p test-workspace-vtt

      - name: Run pipeline on VTT caption
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          CONTAINER_ID=$(docker create \
            -e CLAUDE_CODE_OAUTH_TOKEN="$CLAUDE_CODE_OAUTH_TOKEN" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            run --file /examples/youtube/Anthropics/captions/EvtPBaaykdo.en.vtt \
            --topics "ai,claude,developer-tools" \
            --tone "expert")

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-vtt/
          docker rm "$CONTAINER_ID"

      - name: Validate VTT kit
        run: |
          echo "Validating VTT kit..."
          SESSION_DIR=$(find test-workspace-vtt/contentItem -maxdepth 1 -type d ! -name contentItem | head -1)
          echo "Session folder: $SESSION_DIR"
          jq -e '.contentId and .summary and .ideas and .suggestedOutline' "$SESSION_DIR/writing-kit.json"
          HOOK_COUNT=$(jq '.ideas.hooks | length' "$SESSION_DIR/writing-kit.json")
          SECTION_COUNT=$(jq '.suggestedOutline | length' "$SESSION_DIR/writing-kit.json")
          echo "Hook count: $HOOK_COUNT (expected: >= 2)"
          echo "Outline sections: $SECTION_COUNT (expected: >= 3)"
          [ "$HOOK_COUNT" -ge 2 ] || (echo "Hook count too low" && exit 1)
          [ "$SECTION_COUNT" -ge 3 ] || (echo "Outline section count too low" && exit 1)
          echo "VTT kit valid"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-vtt
          path: test-workspace-vtt/
          retention-days: 7

  # Test 3: SRT Transcript (run command)
  test-srt:
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: gunzip -c looplia-image.tar.gz | docker load

      - name: Create test workspace
        run: mkdir -p test-workspace-srt

      - name: Run pipeline on SRT transcript
        env:
          CLAUDE_CODE_OAUTH_TOKEN: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
        run: |
          CONTAINER_ID=$(docker create \
            -e CLAUDE_CODE_OAUTH_TOKEN="$CLAUDE_CODE_OAUTH_TOKEN" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            run --file /examples/youtube/Anthropics/transcripts/CBneTpXF1CQ.srt \
            --topics "coding,claude,automation" \
            --tone "expert")

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-srt/
          docker rm "$CONTAINER_ID"

      - name: Validate SRT kit
        run: |
          echo "Validating SRT kit..."
          SESSION_DIR=$(find test-workspace-srt/contentItem -maxdepth 1 -type d ! -name contentItem | head -1)
          echo "Session folder: $SESSION_DIR"
          jq -e '.contentId and .summary and .ideas and .suggestedOutline' "$SESSION_DIR/writing-kit.json"
          HOOK_COUNT=$(jq '.ideas.hooks | length' "$SESSION_DIR/writing-kit.json")
          SECTION_COUNT=$(jq '.suggestedOutline | length' "$SESSION_DIR/writing-kit.json")
          echo "Hook count: $HOOK_COUNT (expected: >= 2)"
          echo "Outline sections: $SECTION_COUNT (expected: >= 3)"
          [ "$HOOK_COUNT" -ge 2 ] || (echo "Hook count too low" && exit 1)
          [ "$SECTION_COUNT" -ge 3 ] || (echo "Outline section count too low" && exit 1)
          echo "SRT kit valid"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-srt
          path: test-workspace-srt/
          retention-days: 7

  # LLM-based semantic evaluation using Claude Code Action (manual trigger only)
  semantic-evaluation:
    runs-on: ubuntu-latest
    needs: [test-markdown, test-vtt, test-srt]
    if: github.event_name == 'workflow_dispatch'
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download markdown artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results-markdown
          path: test-workspace/markdown/

      - name: Download VTT artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results-vtt
          path: test-workspace/vtt/

      - name: Download SRT artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results-srt
          path: test-workspace/srt/

      - name: Evaluate pipeline outputs with Claude Code
        uses: anthropics/claude-code-action@v1
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          prompt: |
            You are an evaluator for a content intelligence pipeline. Your task is to assess the quality of WritingKit outputs from 3 different source types: Markdown, VTT, and SRT.

            ## Evaluation Structure

            For each source type, evaluate the WritingKit output using additive criteria (1 point each, max 4):
            - **Accuracy** (1 pt): Summary key facts match the source without fabrication
            - **Completeness** (1 pt): Main themes captured in summary and ideas
            - **Ideas Quality** (1 pt): Hooks, angles, and questions are relevant and engaging
            - **Outline Quality** (1 pt): Suggested outline has logical structure and realistic word counts

            ## Source 1: Markdown (test-workspace/markdown/)
            - Content: test-workspace/markdown/contentItem/*/content.md
            - Kit: test-workspace/markdown/contentItem/*/writing-kit.json

            ## Source 2: VTT Caption (test-workspace/vtt/)
            - Content: test-workspace/vtt/contentItem/*/content.md
            - Kit: test-workspace/vtt/contentItem/*/writing-kit.json

            ## Source 3: SRT Transcript (test-workspace/srt/)
            - Content: test-workspace/srt/contentItem/*/content.md
            - Kit: test-workspace/srt/contentItem/*/writing-kit.json

            ## Output Format
            Print your evaluation:

            === MARKDOWN EVALUATION ===
            - Accuracy: [0/1] - [reason]
            - Completeness: [0/1] - [reason]
            - Ideas Quality: [0/1] - [reason]
            - Outline Quality: [0/1] - [reason]
            Score: [X]/4

            === VTT EVALUATION ===
            - Accuracy: [0/1] - [reason]
            - Completeness: [0/1] - [reason]
            - Ideas Quality: [0/1] - [reason]
            - Outline Quality: [0/1] - [reason]
            Score: [X]/4

            === SRT EVALUATION ===
            - Accuracy: [0/1] - [reason]
            - Completeness: [0/1] - [reason]
            - Ideas Quality: [0/1] - [reason]
            - Outline Quality: [0/1] - [reason]
            Score: [X]/4

            === FINAL RESULT ===
            Total: [X]/12
            Status: [PASS if >= 9, FAIL if < 9]

            If FAIL, use Bash to exit with code 1.
