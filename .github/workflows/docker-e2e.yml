name: Docker E2E Tests

on:
  workflow_dispatch: # Manual trigger
  push:
    branches: [main] # Trigger on merge to main

env:
  IMAGE_NAME: looplia:test

jobs:
  # Build Docker image once and share with all test jobs
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v2
        with:
          bun-version: latest

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Build project
        run: bun run build

      - name: Build Docker image
        run: docker build -t $IMAGE_NAME .

      - name: Save Docker image
        run: docker save $IMAGE_NAME | gzip > looplia-image.tar.gz

      - name: Upload Docker image
        uses: actions/upload-artifact@v4
        with:
          name: docker-image
          path: looplia-image.tar.gz
          retention-days: 1

  # Test 1: Markdown (summarize + kit)
  test-markdown:
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: gunzip -c looplia-image.tar.gz | docker load

      - name: Create test workspace
        run: mkdir -p test-workspace-markdown

      - name: Run summarize command
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          CONTAINER_ID=$(docker create \
            -e ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            summarize --file /examples/ai-healthcare.md \
            --output /home/looplia/.looplia/summary.json)

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-markdown/
          docker rm "$CONTAINER_ID"

      - name: Validate summary schema
        run: |
          echo "Validating summary schema..."
          jq -e '.headline and .tldr and .bullets and .tags' test-workspace-markdown/summary.json
          echo "Summary schema valid"

      - name: Validate summary quality
        run: |
          echo "Checking summary quality metrics..."
          TLDR_WORDS=$(jq -r '.tldr' test-workspace-markdown/summary.json | wc -w)
          BULLET_COUNT=$(jq '.bullets | length' test-workspace-markdown/summary.json)
          TAG_COUNT=$(jq '.tags | length' test-workspace-markdown/summary.json)

          echo "TLDR words: $TLDR_WORDS (expected: 30-200)"
          echo "Bullet count: $BULLET_COUNT (expected: 3-7)"
          echo "Tag count: $TAG_COUNT (expected: >= 3)"

          [ "$BULLET_COUNT" -ge 3 ] || (echo "Bullet count too low" && exit 1)
          [ "$TAG_COUNT" -ge 3 ] || (echo "Tag count too low" && exit 1)

          echo "Summary quality acceptable"

      - name: Run kit command
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          CONTAINER_ID=$(docker create \
            -e ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            kit --file /examples/ai-healthcare.md \
            --topics "ai,healthcare,technology" \
            --tone "expert" \
            --output /home/looplia/.looplia/kit.json)

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-markdown/
          docker rm "$CONTAINER_ID"

      - name: Validate kit schema
        run: |
          echo "Validating kit schema..."
          jq -e '.contentId and .summary and .ideas and .suggestedOutline' test-workspace-markdown/kit.json
          echo "Kit schema valid"

      - name: Validate kit quality
        run: |
          echo "Checking kit quality metrics..."
          HOOK_COUNT=$(jq '.ideas.hooks | length' test-workspace-markdown/kit.json)
          ANGLE_COUNT=$(jq '.ideas.angles | length' test-workspace-markdown/kit.json)
          QUESTION_COUNT=$(jq '.ideas.questions | length' test-workspace-markdown/kit.json)
          SECTION_COUNT=$(jq '.suggestedOutline | length' test-workspace-markdown/kit.json)

          echo "Hook count: $HOOK_COUNT (expected: >= 2)"
          echo "Angle count: $ANGLE_COUNT (expected: >= 2)"
          echo "Question count: $QUESTION_COUNT (expected: >= 2)"
          echo "Outline sections: $SECTION_COUNT (expected: >= 3)"

          [ "$HOOK_COUNT" -ge 2 ] || (echo "Hook count too low" && exit 1)
          [ "$SECTION_COUNT" -ge 3 ] || (echo "Outline section count too low" && exit 1)

          echo "Kit quality acceptable"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-markdown
          path: test-workspace-markdown/
          retention-days: 7

  # Test 2: VTT Caption (kit command)
  test-vtt:
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: gunzip -c looplia-image.tar.gz | docker load

      - name: Create test workspace
        run: mkdir -p test-workspace-vtt

      - name: Run kit on VTT caption
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          CONTAINER_ID=$(docker create \
            -e ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            kit --file /examples/youtube/Anthropics/captions/EvtPBaaykdo.en.vtt \
            --topics "ai,claude,developer-tools" \
            --tone "expert")

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-vtt/
          docker rm "$CONTAINER_ID"

      - name: Validate VTT kit
        run: |
          echo "Validating VTT kit..."
          SESSION_DIR=$(find test-workspace-vtt/contentItem -maxdepth 1 -type d ! -name contentItem | head -1)
          echo "Session folder: $SESSION_DIR"
          jq -e '.contentId and .summary and .ideas and .suggestedOutline' "$SESSION_DIR/writing-kit.json"
          HOOK_COUNT=$(jq '.ideas.hooks | length' "$SESSION_DIR/writing-kit.json")
          SECTION_COUNT=$(jq '.suggestedOutline | length' "$SESSION_DIR/writing-kit.json")
          echo "Hook count: $HOOK_COUNT (expected: >= 2)"
          echo "Outline sections: $SECTION_COUNT (expected: >= 3)"
          [ "$HOOK_COUNT" -ge 2 ] || (echo "Hook count too low" && exit 1)
          [ "$SECTION_COUNT" -ge 3 ] || (echo "Outline section count too low" && exit 1)
          echo "VTT kit valid"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-vtt
          path: test-workspace-vtt/
          retention-days: 7

  # Test 3: SRT Transcript (kit command)
  test-srt:
    runs-on: ubuntu-latest
    needs: build
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Docker image
        uses: actions/download-artifact@v4
        with:
          name: docker-image

      - name: Load Docker image
        run: gunzip -c looplia-image.tar.gz | docker load

      - name: Create test workspace
        run: mkdir -p test-workspace-srt

      - name: Run kit on SRT transcript
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          CONTAINER_ID=$(docker create \
            -e ANTHROPIC_API_KEY="$ANTHROPIC_API_KEY" \
            -v "$(pwd)/examples:/examples:ro" \
            $IMAGE_NAME \
            kit --file /examples/youtube/Anthropics/transcripts/CBneTpXF1CQ.srt \
            --topics "coding,claude,automation" \
            --tone "expert")

          docker start -a "$CONTAINER_ID"
          docker cp "$CONTAINER_ID:/home/looplia/.looplia/." test-workspace-srt/
          docker rm "$CONTAINER_ID"

      - name: Validate SRT kit
        run: |
          echo "Validating SRT kit..."
          SESSION_DIR=$(find test-workspace-srt/contentItem -maxdepth 1 -type d ! -name contentItem | head -1)
          echo "Session folder: $SESSION_DIR"
          jq -e '.contentId and .summary and .ideas and .suggestedOutline' "$SESSION_DIR/writing-kit.json"
          HOOK_COUNT=$(jq '.ideas.hooks | length' "$SESSION_DIR/writing-kit.json")
          SECTION_COUNT=$(jq '.suggestedOutline | length' "$SESSION_DIR/writing-kit.json")
          echo "Hook count: $HOOK_COUNT (expected: >= 2)"
          echo "Outline sections: $SECTION_COUNT (expected: >= 3)"
          [ "$HOOK_COUNT" -ge 2 ] || (echo "Hook count too low" && exit 1)
          [ "$SECTION_COUNT" -ge 3 ] || (echo "Outline section count too low" && exit 1)
          echo "SRT kit valid"

      - name: Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-srt
          path: test-workspace-srt/
          retention-days: 7

  # LLM-based semantic evaluation using Claude Code Action (manual trigger only)
  semantic-evaluation:
    runs-on: ubuntu-latest
    needs: [test-markdown, test-vtt, test-srt]
    if: github.event_name == 'workflow_dispatch'
    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Download markdown artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results-markdown
          path: test-workspace/markdown/

      - name: Download VTT artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results-vtt
          path: test-workspace/vtt/

      - name: Download SRT artifacts
        uses: actions/download-artifact@v4
        with:
          name: test-results-srt
          path: test-workspace/srt/

      - name: Evaluate pipeline outputs with Claude Code
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          prompt: |
            You are an evaluator for a content intelligence pipeline. Your task is to assess the quality of WritingKit outputs from 3 different source types: Markdown, VTT, and SRT.

            ## Evaluation Structure

            For each source type, evaluate the WritingKit output using additive criteria (1 point each, max 4):
            - **Accuracy** (1 pt): Summary key facts match the source without fabrication
            - **Completeness** (1 pt): Main themes captured in summary and ideas
            - **Ideas Quality** (1 pt): Hooks, angles, and questions are relevant and engaging
            - **Outline Quality** (1 pt): Suggested outline has logical structure and realistic word counts

            ## Source 1: Markdown (test-workspace/markdown/)
            - Content: test-workspace/markdown/contentItem/*/content.md
            - Kit: test-workspace/markdown/kit.json

            ## Source 2: VTT Caption (test-workspace/vtt/)
            - Content: test-workspace/vtt/contentItem/*/content.md
            - Kit: test-workspace/vtt/contentItem/*/writing-kit.json

            ## Source 3: SRT Transcript (test-workspace/srt/)
            - Content: test-workspace/srt/contentItem/*/content.md
            - Kit: test-workspace/srt/contentItem/*/writing-kit.json

            ## Output Format
            Print your evaluation:

            === MARKDOWN EVALUATION ===
            - Accuracy: [0/1] - [reason]
            - Completeness: [0/1] - [reason]
            - Ideas Quality: [0/1] - [reason]
            - Outline Quality: [0/1] - [reason]
            Score: [X]/4

            === VTT EVALUATION ===
            - Accuracy: [0/1] - [reason]
            - Completeness: [0/1] - [reason]
            - Ideas Quality: [0/1] - [reason]
            - Outline Quality: [0/1] - [reason]
            Score: [X]/4

            === SRT EVALUATION ===
            - Accuracy: [0/1] - [reason]
            - Completeness: [0/1] - [reason]
            - Ideas Quality: [0/1] - [reason]
            - Outline Quality: [0/1] - [reason]
            Score: [X]/4

            === FINAL RESULT ===
            Total: [X]/12
            Status: [PASS if >= 9, FAIL if < 9]

            If FAIL, use Bash to exit with code 1.
